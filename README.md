# Research Agent Backend

An AI-powered research agent backend that provides research capabilities across multiple domains including medical, academic, knowledge, and web sources. Built with FastAPI, MongoDB, and LangGraph for advanced query processing and response synthesis.

## Introduction

The Research Agent Backend is an intelligent research assistant that automatically classifies user queries and routes them to appropriate data sources. It leverages multiple research databases and web sources to provide comprehensive, well-cited responses. The system uses LangGraph for workflow orchestration and OpenAI's language models for intelligent query processing and response synthesis.

## Research Graph Structure

![Research Graph Structure](graph.png)

The research workflow is orchestrated through a LangGraph-based system that intelligently routes queries through domain-specific processing pipelines.

### Classify
The graph begins with automatic domain classification using OpenAI's language model, which determines whether a query belongs to medical, academic, knowledge, or web domains. 

### Identify
For medical queries, the system includes an additional step to identify and extract relevant medical terms before source retrieval. 

### Retrieve
Once classified and identified, the query is routed to the appropriate source fetchers: PubMed for medical literature, ArXiv for academic papers, Wikipedia for general knowledge, and DuckDuckGo for web search.
If initial results are empty, the system falls back to DuckDuckGo to ensure comprehensive coverage.

### Synthesize
Once sources are successfully retrieved, response synthesis with inline citations is performed, creating a robust research pipeline that guarantees meaningful results across all domains.

## Quick Start with Docker

The easiest way to get started is using Docker Compose, which sets up the application with MongoDB:

### Prerequisites

- Docker and Docker Compose installed
- OpenAI API key
- PubMed API key (optional, for medical research)

### Environment Setup

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd research-agent/backend
   ```

2. **Configure environment variables **:
   The application uses the following environment variables (Please configure in docker-compose.yml):
   - `OPENAI_API_KEY`: Your OpenAI API key
   - `PUBMED_API_KEY`: PubMed API key
   - `PUBMED_EMAIL`: Email for PubMed API

3. **Start the services**:
   ```bash
   docker compose up --build
   ```

4. **Access the application**:
   - API: http://localhost:8000
   - Interactive API docs: http://localhost:8000/docs
   - Redoc API docs: http://localhost:8000/redoc
   - MongoDB: localhost:27017

### Development Mode

For development with live reload:
```bash
docker compose up --build
```

The application will automatically reload when you make changes to the code.

## Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                         # FastAPI application entry point
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ agents.py                   # Agent management API endpoints
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ db.py                       # Database connection and initialization
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”‚   â””â”€â”€ models.py               # MongoDB data models (AgentInDB, ConversationInDB)
â”‚   â”‚   â””â”€â”€ repositories/
â”‚   â”‚       â””â”€â”€ agent_repository.py     # Repository layer for agent entities
â”‚   â”œâ”€â”€ fetchers/                       # Research source integrations
â”‚   â”‚   â”œâ”€â”€ arxiv.py                    # ArXiv academic papers
â”‚   â”‚   â”œâ”€â”€ pubmed.py                   # PubMed medical literature
â”‚   â”‚   â”œâ”€â”€ wikipedia.py                # Wikipedia knowledge base
â”‚   â”‚   â””â”€â”€ duckduckgo.py               # Web search capabilities
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ requests.py                 # API request models (AgentCreate, AgentQueries)
â”‚   â”‚   â”œâ”€â”€ response.py                 # API response models (AgentOut, ConversationsOut)
â”‚   â”‚   â””â”€â”€ results.py                  # Research result models (QueryResult, FetcherResult)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ research_service.py         # Core business logic
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ llm.py                      # LLM configuration and utilities
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ research_graph.py           # LangGraph workflow orchestration
â”‚       â”œâ”€â”€ research_state.py           # Workflow state management (ResearchState)
â”‚       â””â”€â”€ research_type.py            # Domain classification types (ResearchType)
â”œâ”€â”€ tests/                              # Comprehensive test suite
â”‚   â”œâ”€â”€ test_agents_api.py              # API endpoint tests
â”‚   â”œâ”€â”€ test_research_graph.py          # Workflow tests
â”‚   â”œâ”€â”€ test_research_service.py        # Service layer tests
â”‚   â””â”€â”€ test_agent_repository.py        # Repository layer tests
â”œâ”€â”€ docker-compose.yml                  # Multi-service Docker setup
â”œâ”€â”€ Dockerfile                          # Application containerization
â”œâ”€â”€ requirements.txt                    # Python dependencies
â””â”€â”€ pytest.ini                          # Test configuration
```
## Testing

### Local Testing
```bash
# Install dependencies
uv pip install -r requirements.txt

# Run all tests with verbose output
pytest -v
```

## Features

### ğŸ” Intelligent Research Capabilities

- **Domain-Aware Processing**: Automatically classifies queries into appropriate research domains
- **Multi-Source Integration with Fallback**: 
  - **Medical**: PubMed for clinical and medical literature
  - **Academic**: ArXiv for scientific papers and research
  - **Knowledge**: Wikipedia for general knowledge and facts
  - **Web**: DuckDuckGo for current events and general web information
- **Fallback Mechanism**: Search queries automatically fall back to web search when it returns empty results

### ğŸ¤– AI-Powered Features

- **Smart Query Classification**: Uses OpenAI to determine the most appropriate research domain
- **Medical Term Extraction**: Specialized processing for medical queries
- **Response Synthesis**: Generates comprehensive, well-cited responses
- **Source Attribution**: Provides inline citations and source references

### ğŸ›  Technical Features

- **FastAPI Framework**: High-performance, modern Python web framework
- **MongoDB Integration**: Scalable document database with Beanie ODM
- **LangGraph Workflows**: Advanced workflow orchestration for research processes
- **Comprehensive Testing**: Full test suite with pytest and httpx
- **Docker Support**: Containerized deployment with multi-service setup
- **RESTful API**: Clean, well-documented API endpoints

## Prerequisites

### System Requirements

- **Python**: 3.12+ (if running locally)
- **Docker**: 20.10+ (recommended)
- **Docker Compose**: 2.0+ (recommended)

### API Keys Required

1. **OpenAI API Key** (Required)
   - Sign up at https://platform.openai.com/
   - Generate an API key
   - Add to environment variables

2. **PubMed API Key** (Required for medical research)
   - Register at https://www.ncbi.nlm.nih.gov/account/
   - Generate API key
   - Add to environment variables

### Dependencies

The application requires the following key dependencies (see `requirements.txt`):

- **Web Framework**: FastAPI, Starlette, Uvicorn
- **Database**: Beanie (MongoDB ODM), Motor, PyMongo
- **AI/ML**: OpenAI, LangGraph, LangChain
- **Research Sources**: ArXiv, Wikipedia, DuckDuckGo, PubMed
- **Testing**: Pytest, HTTPX
- **Utilities**: PyMuPDF, xmltodict
